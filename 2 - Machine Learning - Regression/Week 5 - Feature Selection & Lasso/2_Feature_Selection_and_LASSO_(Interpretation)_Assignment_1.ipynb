{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "2 - Feature Selection and LASSO (Interpretation) - Assignment 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zuyuf/Machine_Learning_Specialization/blob/main/2%20-%20Machine%20Learning%20-%20Regression/Week%205%20-%20Feature%20Selection%20%26%20Lasso/2_Feature_Selection_and_LASSO_(Interpretation)_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TM7_L3gUOOu",
        "outputId": "3e3b3124-3db6-45e8-eac4-d425a1a71a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install turicreate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting turicreate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/38/77a081ce35f012bd4789551db9e5196e766a2641cb05114ded9cc268182c/turicreate-6.4.1-cp27-cp27mu-manylinux1_x86_64.whl (91.9MB)\n",
            "\u001b[K     |████████████████████████████████| 91.9MB 101kB/s \n",
            "\u001b[?25hCollecting pillow>=5.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/ad/61f8dfba88c4e56196bf6d056cdbba64dc9c5dfdfbc97d02e6472feed913/Pillow-6.2.2-cp27-cp27mu-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from turicreate) (1.16.4)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python2.7/dist-packages (from turicreate) (2.23.0)\n",
            "Collecting tensorflow<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/08/1ff15637a03b1565dd6cb0916b3ca6873db3a1fc69be0ed851be936e5633/tensorflow-2.0.0-cp27-cp27mu-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: prettytable==0.7.2 in /usr/local/lib/python2.7/dist-packages (from turicreate) (0.7.2)\n",
            "Collecting llvmlite==0.31.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/07/90cd9cdd43b287960b16dbf7929bff2267dc0b6647e8e0117a4937b19620/llvmlite-0.31.0-cp27-cp27mu-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python2.7/dist-packages (from turicreate) (0.24.2)\n",
            "Requirement already satisfied: numba<0.51.0 in /usr/local/lib/python2.7/dist-packages (from turicreate) (0.40.1)\n",
            "Requirement already satisfied: decorator>=4.0.9 in /usr/local/lib/python2.7/dist-packages (from turicreate) (4.4.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from turicreate) (1.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from turicreate) (1.15.0)\n",
            "Requirement already satisfied: resampy==0.2.1 in /usr/local/lib/python2.7/dist-packages (from turicreate) (0.2.1)\n",
            "Collecting coremltools==3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/9b/f6feac5d9369c68ee718d3c3140435452773a36ff08ef3bcc4fe378e8676/coremltools-3.3-cp27-none-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.9.1->turicreate) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.9.1->turicreate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.9.1->turicreate) (2019.6.16)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.9.1->turicreate) (2.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.15.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/3d/993131c622ae34f9401a81526853f2310a4834bd042420a7982fb5bc5fd0/tensorboard-2.0.2-py2-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.0)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.post1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.35.1)\n",
            "Requirement already satisfied: functools32>=3.2.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.2.3.post2)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.0.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (2.3.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.1.7)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.6)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.8.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas>=0.23.2->turicreate) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.23.2->turicreate) (2.5.3)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python2.7/dist-packages (from numba<0.51.0->turicreate) (1.0.2)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python2.7/dist-packages (from numba<0.51.0->turicreate) (3.4.0.3)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow<2.1.0,>=2.0.0->turicreate) (3.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (44.1.1)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.15.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.8->tensorflow<2.1.0,>=2.0.0->turicreate) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (5.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1; python_version < \"3\" in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.0.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa<4.1; python_version < \"3\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.5)\n",
            "\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, google-auth-oauthlib, tensorboard, tensorflow-estimator, tensorflow, llvmlite, coremltools, turicreate\n",
            "  Found existing installation: Pillow 4.3.0\n",
            "    Uninstalling Pillow-4.3.0:\n",
            "      Successfully uninstalled Pillow-4.3.0\n",
            "  Found existing installation: google-auth-oauthlib 0.4.0\n",
            "    Uninstalling google-auth-oauthlib-0.4.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.0\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBn2Hv21fIv-",
        "outputId": "29f4ad8f-51b9-484c-be61-d6c6842895e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miyhlTMAuGTE"
      },
      "source": [
        "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejHOt-3MuGTF"
      },
      "source": [
        "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using Turi Create, though you can use other solvers). You will:\n",
        "* Run LASSO with different L1 penalties.\n",
        "* Choose best L1 penalty using a validation set.\n",
        "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
        "\n",
        "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPoZQoBruGTG"
      },
      "source": [
        "# Fire up Turi Create"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMegZg4nuGTG"
      },
      "source": [
        "import turicreate\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPvoXwQMuGTJ"
      },
      "source": [
        "# Load in house sales data\n",
        "\n",
        "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZOdCiI4GuGTK"
      },
      "source": [
        "resource_dir = '/content/gdrive/My Drive/Turicreate/2 - ML - Regression/WEEK 5 - Feature Selection & Lasso/0 - Resources/'\n",
        "sales = turicreate.SFrame(resource_dir + 'home_data.sframe/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uP__-j4uGTM"
      },
      "source": [
        "# Create new features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOSDnyI4uGTN"
      },
      "source": [
        "As in Week 2, we consider features that are some transformations of inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcbZKXDVuGTN"
      },
      "source": [
        "from math import log, sqrt\n",
        "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
        "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
        "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
        "\n",
        "# In the dataset, 'floors' was defined with type string, \n",
        "# so we'll convert them to float, before creating a new feature.\n",
        "sales['floors'] = sales['floors'].astype(float) \n",
        "sales['floors_square'] = sales['floors']*sales['floors']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKLzwbVYuGTP"
      },
      "source": [
        "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
        "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-iUPWh9uGTQ"
      },
      "source": [
        "# Learn regression weights with L1 penalty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOMZ6QPIuGTQ"
      },
      "source": [
        "Let us fit a model with all the features available, plus the features we just created above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KhBdMQhuGTR"
      },
      "source": [
        "all_features = ['bedrooms', 'bedrooms_square',\n",
        "                'bathrooms',\n",
        "                'sqft_living', 'sqft_living_sqrt',\n",
        "                'sqft_lot', 'sqft_lot_sqrt',\n",
        "                'floors', 'floors_square',\n",
        "                'waterfront', 'view', 'condition', 'grade',\n",
        "                'sqft_above',\n",
        "                'sqft_basement',\n",
        "                'yr_built', 'yr_renovated']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcJrX7oLuGTT"
      },
      "source": [
        "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in Turi Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K-Q0-HDuGTU",
        "outputId": "50604b2d-1dbc-4c95-cb7f-d7f676ad97a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model_all = turicreate.linear_regression.create(sales, target='price', features=all_features,\n",
        "                                                validation_set=None, \n",
        "                                                l2_penalty=0., l1_penalty=1e10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Linear regression:"
            ],
            "text/html": [
              "<pre>Linear regression:</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------------------------------------"
            ],
            "text/html": [
              "<pre>--------------------------------------------------------</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Number of examples          : 21613"
            ],
            "text/html": [
              "<pre>Number of examples          : 21613</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Number of features          : 17"
            ],
            "text/html": [
              "<pre>Number of features          : 17</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Number of unpacked features : 17"
            ],
            "text/html": [
              "<pre>Number of unpacked features : 17</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Number of coefficients    : 18"
            ],
            "text/html": [
              "<pre>Number of coefficients    : 18</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Starting Accelerated Gradient (FISTA)"
            ],
            "text/html": [
              "<pre>Starting Accelerated Gradient (FISTA)</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------------------------------------"
            ],
            "text/html": [
              "<pre>--------------------------------------------------------</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tuning step size. First iteration could take longer than subsequent iterations."
            ],
            "text/html": [
              "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----------+----------+-----------+--------------+--------------------+---------------------------------+"
            ],
            "text/html": [
              "<pre>+-----------+----------+-----------+--------------+--------------------+---------------------------------+</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| Iteration | Passes   | Step size | Elapsed Time | Training Max Error | Training Root-Mean-Square Error |"
            ],
            "text/html": [
              "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Max Error | Training Root-Mean-Square Error |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----------+----------+-----------+--------------+--------------------+---------------------------------+"
            ],
            "text/html": [
              "<pre>+-----------+----------+-----------+--------------+--------------------+---------------------------------+</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 0         | 1        | 1.000000  | 1.014350     | 7700000.000000     | 653047.733994                   |"
            ],
            "text/html": [
              "<pre>| 0         | 1        | 1.000000  | 1.014350     | 7700000.000000     | 653047.733994                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 1         | 2        | 0.000002  | 1.477755     | 6962915.603493     | 426631.749026                   |"
            ],
            "text/html": [
              "<pre>| 1         | 2        | 0.000002  | 1.477755     | 6962915.603493     | 426631.749026                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 2         | 3        | 0.000002  | 1.519029     | 6843144.200219     | 392488.929838                   |"
            ],
            "text/html": [
              "<pre>| 2         | 3        | 0.000002  | 1.519029     | 6843144.200219     | 392488.929838                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 3         | 4        | 0.000002  | 1.562028     | 6831900.032123     | 385340.166783                   |"
            ],
            "text/html": [
              "<pre>| 3         | 4        | 0.000002  | 1.562028     | 6831900.032123     | 385340.166783                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 4         | 5        | 0.000002  | 1.610682     | 6847166.848958     | 384842.383767                   |"
            ],
            "text/html": [
              "<pre>| 4         | 5        | 0.000002  | 1.610682     | 6847166.848958     | 384842.383767                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 5         | 6        | 0.000002  | 1.659810     | 6869667.895833     | 385998.458623                   |"
            ],
            "text/html": [
              "<pre>| 5         | 6        | 0.000002  | 1.659810     | 6869667.895833     | 385998.458623                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "| 10        | 11       | 0.000002  | 1.877357     | 6842123.232651     | 364204.576180                   |"
            ],
            "text/html": [
              "<pre>| 10        | 11       | 0.000002  | 1.877357     | 6842123.232651     | 364204.576180                   |</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "+-----------+----------+-----------+--------------+--------------------+---------------------------------+"
            ],
            "text/html": [
              "<pre>+-----------+----------+-----------+--------------+--------------------+---------------------------------+</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Completed (Iteration limit reached)."
            ],
            "text/html": [
              "<pre>Completed (Iteration limit reached).</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "This model may not be optimal. To improve it, consider increasing `max_iterations`."
            ],
            "text/html": [
              "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2ypqrAIuGTW"
      },
      "source": [
        "Find what features had non-zero weight."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWalUFlpuGTW",
        "outputId": "a849f946-32c6-490c-ca46-3b5545930803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "non_zero_weights = model_all.coefficients[ model_all.coefficients['value'] > 0 ]\n",
        "non_zero_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Columns:\n",
              "\tname\tstr\n",
              "\tindex\tstr\n",
              "\tvalue\tfloat\n",
              "\tstderr\tfloat\n",
              "\n",
              "Rows: Unknown\n",
              "\n",
              "Data:\n",
              "+------------------+-------+---------------+--------+\n",
              "|       name       | index |     value     | stderr |\n",
              "+------------------+-------+---------------+--------+\n",
              "|   (intercept)    |  None |  274873.05595 |  None  |\n",
              "|    bathrooms     |  None | 8468.53108691 |  None  |\n",
              "|   sqft_living    |  None | 24.4207209824 |  None  |\n",
              "| sqft_living_sqrt |  None | 350.060553386 |  None  |\n",
              "|      grade       |  None | 842.068034898 |  None  |\n",
              "|    sqft_above    |  None | 20.0247224171 |  None  |\n",
              "+------------------+-------+---------------+--------+\n",
              "[? rows x 4 columns]\n",
              "Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.\n",
              "You can use sf.materialize() to force materialization."
            ],
            "text/html": [
              "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
              "    <tr>\n",
              "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
              "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
              "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">value</th>\n",
              "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">stderr</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(intercept)</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">274873.05595</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">bathrooms</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8468.53108691</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sqft_living</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">24.4207209824</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sqft_living_sqrt</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">350.060553386</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">grade</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">842.068034898</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">sqft_above</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">20.0247224171</td>\n",
              "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
              "    </tr>\n",
              "</table>\n",
              "[? rows x 4 columns]<br/>Note: Only the head of the SFrame is printed. This SFrame is lazily evaluated.<br/>You can use sf.materialize() to force materialization.\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0xnyS6CuGTZ"
      },
      "source": [
        "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
        "\n",
        "***QUIZ QUESTION***:\n",
        "According to this list of weights, which of the features have been chosen? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGODofb9uGTZ"
      },
      "source": [
        "# Selecting an L1 penalty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLUkehwnuGTZ"
      },
      "source": [
        "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
        "* Split our sales data into 2 sets: training and test\n",
        "* Further split our training data into two sets: train, validation\n",
        "\n",
        "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVFatciDuGTa"
      },
      "source": [
        "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
        "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z5mgzbSuGTc"
      },
      "source": [
        "Next, we write a loop that does the following:\n",
        "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
        "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
        "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
        "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
        "\n",
        "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
        "\n",
        "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7WaYtqgyli0",
        "outputId": "550991c8-75de-4b5f-c07e-721e14c4ab19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pprint\n",
        "validation_RSS = {}\n",
        "\n",
        "for l1_penalty in np.logspace(1, 7, num=13):\n",
        "    model = turicreate.linear_regression.create( training, target='price', features=all_features, \n",
        "                                                  l2_penalty=0, l1_penalty=l1_penalty, \n",
        "                                                  validation_set=None, verbose=False)\n",
        "    \n",
        "    predictions = model.predict(validation)\n",
        "    residuals = validation['price'] - predictions\n",
        "    RSS = sum( residuals ** 2 )\n",
        "\n",
        "    validation_RSS[l1_penalty] = RSS\n",
        "\n",
        "pprint.pprint(validation_RSS)\n",
        "print min(validation_RSS.items(), key= lambda x: x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{10.0: 625766285142461.4,\n",
            " 31.622776601683793: 625766285362395.2,\n",
            " 100.0: 625766286057886.9,\n",
            " 316.22776601683796: 625766288257224.9,\n",
            " 1000.0: 625766295212185.9,\n",
            " 3162.2776601683795: 625766317206077.8,\n",
            " 10000.0: 625766386760661.5,\n",
            " 31622.776601683792: 625766606749281.4,\n",
            " 100000.0: 625767302791633.4,\n",
            " 316227.7660168379: 625769507643885.0,\n",
            " 1000000.0: 625776517727025.9,\n",
            " 3162277.6601683795: 625799062845466.9,\n",
            " 10000000.0: 625883719085424.5}\n",
            "(10.0, 625766285142461.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RDqBdVjuGTh"
      },
      "source": [
        "### **QUIZ QUESTION**\n",
        "- What was the best value for the `l1_penalty`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNFhJzliuGTh",
        "outputId": "6b850343-4795-4a0c-e4bf-a11af5649cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_l1_penalty = min(validation_RSS.items(), key= lambda x: x[1])\n",
        "best_l1_penalty"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10.0, 625766285142461.4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0koOZTX00ZO"
      },
      "source": [
        "- What is the RSS on TEST data of the model with the best `l1_penalty`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGIwT2K010v",
        "outputId": "6255f426-7498-4955-afa2-93215309244a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_l1_model = turicreate.linear_regression.create(training, target='price', features=all_features,\n",
        "                                                      l2_penalty=0, l1_penalty=best_l1_penalty[0],\n",
        "                                                      validation_set=None, verbose=False)\n",
        "\n",
        "predictions_test = best_l1_model.predict(testing)\n",
        "residuals_test = testing['price'] - predictions_test\n",
        "RSS_test = sum( residuals_test ** 2 )\n",
        "\n",
        "print RSS_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.56983602382e+14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkJF5C6PuGTk"
      },
      "source": [
        "***QUIZ QUESTION***\n",
        "Also, using this value of L1 penalty, how many nonzero weights do you have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82FeKYR7uGTk",
        "outputId": "97a02c07-cfac-40c6-c6c0-1aebd2f98d7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_l1_weights = best_l1_model.coefficients[best_l1_model.coefficients['value'] > 0]\n",
        "best_l1_weights.print_rows(num_rows=18)\n",
        "len(best_l1_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+-------+------------------+--------+\n",
            "|       name       | index |      value       | stderr |\n",
            "+------------------+-------+------------------+--------+\n",
            "|   (intercept)    |  None |  18993.4272128   |  None  |\n",
            "|     bedrooms     |  None |  7936.96767903   |  None  |\n",
            "| bedrooms_square  |  None |  936.993368193   |  None  |\n",
            "|    bathrooms     |  None |  25409.5889341   |  None  |\n",
            "|   sqft_living    |  None |  39.1151363797   |  None  |\n",
            "| sqft_living_sqrt |  None |  1124.65021281   |  None  |\n",
            "|     sqft_lot     |  None | 0.00348361822299 |  None  |\n",
            "|  sqft_lot_sqrt   |  None |  148.258391011   |  None  |\n",
            "|      floors      |  None |   21204.335467   |  None  |\n",
            "|  floors_square   |  None |  12915.5243361   |  None  |\n",
            "|    waterfront    |  None |  601905.594545   |  None  |\n",
            "|       view       |  None |  93312.8573119   |  None  |\n",
            "|    condition     |  None |  6609.03571245   |  None  |\n",
            "|      grade       |  None |  6206.93999188   |  None  |\n",
            "|    sqft_above    |  None |  43.2870534193   |  None  |\n",
            "|  sqft_basement   |  None |  122.367827534   |  None  |\n",
            "|     yr_built     |  None |  9.43363539372   |  None  |\n",
            "|   yr_renovated   |  None |  56.0720034488   |  None  |\n",
            "+------------------+-------+------------------+--------+\n",
            "[18 rows x 4 columns]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPt39B2xuGTm"
      },
      "source": [
        "# Limit the number of nonzero weights\n",
        "\n",
        "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEV2k5HEuGTn"
      },
      "source": [
        "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
        "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
        "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMelO6_vuGTn"
      },
      "source": [
        "max_nonzeros = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWAHGkp9uGTr"
      },
      "source": [
        "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
        "\n",
        "Let's define a wide range of possible `l1_penalty_values`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ_Szj7LuGTt"
      },
      "source": [
        "l1_penalty_values = np.logspace(8, 10, num=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GasRgn4UuGTy"
      },
      "source": [
        "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
        "\n",
        "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
        "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
        "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
        "        * *Hint: `model.coefficients['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnSiCncduGT0",
        "outputId": "f2aaddc1-8835-47ea-b68b-868cd07fd31e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "store_NNZ = {}\n",
        "\n",
        "for l1_penalty in l1_penalty_values:\n",
        "  model = turicreate.linear_regression.create(training, target='price', features=all_features,\n",
        "                                                validation_set=None, verbose=False,\n",
        "                                                l2_penalty=0, l1_penalty=l1_penalty)\n",
        "  \n",
        "  store_NNZ[l1_penalty] = model.coefficients['value'].nnz()\n",
        "\n",
        "pprint.pprint(store_NNZ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{100000000.0: 18,\n",
            " 127427498.57031322: 18,\n",
            " 162377673.91887242: 18,\n",
            " 206913808.111479: 18,\n",
            " 263665089.87303555: 17,\n",
            " 335981828.6283788: 17,\n",
            " 428133239.8719396: 17,\n",
            " 545559478.1168514: 17,\n",
            " 695192796.1775591: 17,\n",
            " 885866790.4100832: 16,\n",
            " 1128837891.6846883: 15,\n",
            " 1438449888.2876658: 15,\n",
            " 1832980710.8324375: 13,\n",
            " 2335721469.0901213: 12,\n",
            " 2976351441.6313133: 10,\n",
            " 3792690190.7322536: 6,\n",
            " 4832930238.571753: 5,\n",
            " 6158482110.6602545: 3,\n",
            " 7847599703.514623: 1,\n",
            " 10000000000.0: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvWxCMzFuGT6"
      },
      "source": [
        "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
        "\n",
        "More formally, find:\n",
        "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
        "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
        "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
        "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
        "\n",
        "\n",
        "*Hint: there are many ways to do this, e.g.:*\n",
        "* Programmatically within the loop above\n",
        "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iOJaC9FuGT7"
      },
      "source": [
        "l1_penalty_min = 2976351441.6313133     # 10 non-zero weights\n",
        "l1_penalty_max = 3792690190.7322536     # 6 non-zero weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hd3x4abvuGT_"
      },
      "source": [
        "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6_I5djsuGUB"
      },
      "source": [
        "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
        "\n",
        "We will now explore the narrow region of `l1_penalty` values we found:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Guf7xjWuGUB"
      },
      "source": [
        "l1_penalty_values_linespace = np.linspace(l1_penalty_min, l1_penalty_max, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz5F-9WDuGUI"
      },
      "source": [
        "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
        "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
        "    * Measure the RSS of the learned model on the VALIDATION set\n",
        "\n",
        "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3NhaDapuGUJ"
      },
      "source": [
        "validation_RSS = {}\n",
        "\n",
        "for l1_penalty in l1_penalty_values_linespace:\n",
        "  model = turicreate.linear_regression.create(training, target='price', features=all_features,\n",
        "                                                l2_penalty=0, l1_penalty=l1_penalty,\n",
        "                                                validation_set=None, verbose=False)\n",
        "  \n",
        "  predictions = model.predict(validation)\n",
        "  residuals = validation['price'] - predictions\n",
        "  RSS = sum(residuals ** 2)\n",
        "\n",
        "  validation_RSS[l1_penalty] = (RSS, model.coefficients['value'].nnz())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BGILzNgAKSn",
        "outputId": "ee94dce3-6ed2-48d0-f493-d0add8d2fba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_RSS = float('inf')\n",
        "best_l1 = None\n",
        "for k, v in validation_RSS.iteritems():\n",
        "  if (v[1] == max_nonzeros) and (v[0] < best_RSS):\n",
        "    best_RSS = v[0]\n",
        "    best_l1 = k\n",
        "\n",
        "print best_l1, best_RSS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3448968612.163437 1.04693748875e+15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBOoc6spuGUO"
      },
      "source": [
        "***QUIZ QUESTIONS***\n",
        "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
        "2. What features in this model have non-zero coefficients?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNyzRGSfuGUP"
      },
      "source": [
        "model = turicreate.linear_regression.create(training, target='price', features=all_features,\n",
        "                                              validation_set=None, verbose = False,\n",
        "                                              l2_penalty=0., l1_penalty=best_l1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJXmSYr4CZif",
        "outputId": "067baef3-87b4-416f-bf5b-4ec51e764c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "non_zero_weight_test = model.coefficients[ model.coefficients[\"value\"] > 0 ]\n",
        "non_zero_weight_test.print_rows(num_rows=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+-------+---------------+--------+\n",
            "|       name       | index |     value     | stderr |\n",
            "+------------------+-------+---------------+--------+\n",
            "|   (intercept)    |  None | 222253.192544 |  None  |\n",
            "|     bedrooms     |  None | 661.722717782 |  None  |\n",
            "|    bathrooms     |  None | 15873.9572593 |  None  |\n",
            "|   sqft_living    |  None | 32.4102214513 |  None  |\n",
            "| sqft_living_sqrt |  None | 690.114773313 |  None  |\n",
            "|      grade       |  None | 2899.42026975 |  None  |\n",
            "|    sqft_above    |  None | 30.0115753022 |  None  |\n",
            "+------------------+-------+---------------+--------+\n",
            "[7 rows x 4 columns]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}